{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c3d5b-8ac7-4349-8588-9c2df9b0c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0b97cab3-5364-4b99-9c0f-e6edecab275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('mushroom_mixed_50000.csv')\n",
    "\n",
    "# Identify the target column\n",
    "target_column = 'class'  # Change this if the target column name is different\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "# Convert categorical target column to numeric labels (if necessary)\n",
    "if y.dtype == 'object':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply One-Hot Encoding to categorical columns\n",
    "X = pd.get_dummies(X, columns=categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b2bb5272-780c-4445-8235-d2289b5d490a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows of Features (X):\n",
      "   cap-diameter  stem-height  stem-width  cap-shape_b  cap-shape_c  \\\n",
      "0          9.39         9.04       16.26        False        False   \n",
      "1         15.42         6.15       32.78        False        False   \n",
      "2          6.07         6.80        6.53        False        False   \n",
      "3          4.64         8.37        6.52        False        False   \n",
      "4         17.87        19.03       18.39        False        False   \n",
      "5          7.96         7.81       20.94        False        False   \n",
      "6          5.64         4.10        6.34        False        False   \n",
      "7          3.05         4.85        4.20         True        False   \n",
      "8         15.67         6.43       30.60        False        False   \n",
      "9          8.49         6.04       24.96        False        False   \n",
      "\n",
      "   cap-shape_f  cap-shape_o  cap-shape_p  cap-shape_s  cap-shape_x  ...  \\\n",
      "0         True        False        False        False        False  ...   \n",
      "1         True        False        False        False        False  ...   \n",
      "2        False        False        False         True        False  ...   \n",
      "3        False        False        False        False         True  ...   \n",
      "4         True        False        False        False        False  ...   \n",
      "5        False        False        False        False         True  ...   \n",
      "6         True        False        False        False        False  ...   \n",
      "7        False        False        False        False        False  ...   \n",
      "8        False        False        False         True        False  ...   \n",
      "9         True        False        False        False        False  ...   \n",
      "\n",
      "   habitat_h  habitat_l  habitat_m  habitat_p  habitat_u  habitat_w  season_a  \\\n",
      "0      False      False      False      False      False      False     False   \n",
      "1      False      False      False      False      False      False     False   \n",
      "2      False      False      False      False      False      False      True   \n",
      "3      False      False      False      False      False      False     False   \n",
      "4      False      False      False      False      False      False     False   \n",
      "5      False      False      False      False      False      False      True   \n",
      "6      False      False      False      False      False      False     False   \n",
      "7      False      False      False      False      False      False     False   \n",
      "8      False      False      False      False      False      False     False   \n",
      "9      False      False      False      False      False      False     False   \n",
      "\n",
      "   season_s  season_u  season_w  \n",
      "0     False      True     False  \n",
      "1     False      True     False  \n",
      "2     False     False     False  \n",
      "3      True     False     False  \n",
      "4     False      True     False  \n",
      "5     False     False     False  \n",
      "6     False      True     False  \n",
      "7     False      True     False  \n",
      "8     False     False      True  \n",
      "9      True     False     False  \n",
      "\n",
      "[10 rows x 127 columns]\n",
      "\n",
      "First 10 rows of Target (y):\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    0\n",
      "Name: class, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Ensure y is a Pandas Series\n",
    "y = pd.Series(y, name=target_column)\n",
    "\n",
    "print(\"First 10 rows of Features (X):\")\n",
    "print(X.head(10))\n",
    "\n",
    "print(\"\\nFirst 10 rows of Target (y):\")\n",
    "print(y.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b888b-fab3-4b11-9dbd-3bd1eb1c3933",
   "metadata": {},
   "source": [
    "## Code for Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c8b3eb87-f7a5-48af-a150-3e7df50add76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decision_tree(param_grid, folds=10):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    best_params_overall = None\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]  # Indexing directly for numpy array\n",
    "\n",
    "        # Initialize DecisionTreeClassifier\n",
    "        clf = DecisionTreeClassifier(random_state=0)\n",
    "        \n",
    "        # Use GridSearchCV to find the best parameters\n",
    "        grid_search = GridSearchCV(clf, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        best_params_overall = best_params\n",
    "        \n",
    "        print(f\"Fold {fold}: Best parameters: {best_params}\")\n",
    "        \n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        print(f\"Fold {fold}: Accuracy: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"Fold {fold}: Confusion Matrix:\\n{cm}\\n\")\n",
    "        \n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    \n",
    "    final_model = grid_search.best_estimator_\n",
    "    final_accuracy = accuracy_score(y, final_model.predict(X))\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Final mean accuracy over {folds} folds: {mean_accuracy * 100:.2f}%\")\n",
    "    print(f\"Final standard deviation of accuracy over {folds} folds: {std_accuracy * 100:.2f}%\")\n",
    "    print(f\"Final accuracy of the model on the entire dataset: {final_accuracy * 100:.2f}%\")\n",
    "    print(f\"Total execution time: {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"\\nBest parameters overall: {best_params_overall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a6e0f2-3c82-4e86-bd97-5f2e8ce3b0ef",
   "metadata": {},
   "source": [
    "## Code for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "da9d4021-f321-4b7e-8eff-043ff24b11aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest(param_grid, folds=10):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    best_params_overall = None\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]  # Ensuring correct indexing for Pandas DataFrame\n",
    "\n",
    "        # Initialize RandomForestClassifier\n",
    "        clf = RandomForestClassifier(random_state=42)\n",
    "        \n",
    "        # Perform GridSearchCV to find the best parameters\n",
    "        grid_search = GridSearchCV(clf, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        best_params_overall = best_params\n",
    "        \n",
    "        print(f\"Fold {fold}: Best parameters: {best_params}\")\n",
    "        \n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        print(f\"Fold {fold}: Accuracy: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"Fold {fold}: Confusion Matrix:\\n{cm}\\n\")\n",
    "        \n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    \n",
    "    final_model = grid_search.best_estimator_\n",
    "    final_accuracy = accuracy_score(y, final_model.predict(X))\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Final mean accuracy over {folds} folds: {mean_accuracy * 100:.2f}%\")\n",
    "    print(f\"Final standard deviation of accuracy over {folds} folds: {std_accuracy * 100:.2f}%\")\n",
    "    print(f\"Final accuracy of the model on the entire dataset: {final_accuracy * 100:.2f}%\")\n",
    "    print(f\"Total execution time: {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"\\nBest parameters overall: {best_params_overall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850837a5",
   "metadata": {},
   "source": [
    "## Code for Nearest Neighbour Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d47c2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to run K-Nearest Neighbors with GridSearchCV\n",
    "def run_knn(param_grid, folds=10):\n",
    "    start_time = time.time()\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    best_params_overall = None\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Initialize KNN Classifier\n",
    "        clf_knn = KNeighborsClassifier()\n",
    "\n",
    "        # Use GridSearchCV to find the best parameters\n",
    "        grid_search = GridSearchCV(clf_knn, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get the best model and parameters\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        best_params_overall = best_params\n",
    "\n",
    "        # Predict on the test set using the best model\n",
    "        y_pred_knn = best_model.predict(X_test)\n",
    "\n",
    "        # Compute accuracy for this fold\n",
    "        accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "    # Calculate mean accuracy across folds\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    return mean_accuracy * 100, best_params_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7422d-028a-4c12-991f-0ea48b7c4ad2",
   "metadata": {},
   "source": [
    "## Runs of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406ce73-fd46-41a4-8a65-aa58f9307bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [3, 5, 10],  # Remove None to avoid deep trees\n",
    "    'min_samples_split': [5, 10, 20],  # Increase min_samples_split to force generalization\n",
    "    'min_samples_leaf': [2, 4, 10],  # Increase min_samples_leaf\n",
    "    'ccp_alpha': [0.01, 0.05, 0.1]  # Apply pruning\n",
    "}\n",
    "\n",
    "\n",
    "print(\"Running Decision Tree with 10 folds:\")\n",
    "run_decision_tree(param_grid)\n",
    "\n",
    "print(\"\\nRunning Decision Tree with 20 folds:\")\n",
    "run_decision_tree(param_grid, folds=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7391dee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef1572-98d5-47c0-b021-c9ea185f5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_2 = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [7, 9, 12],  # Slightly deeper to regain accuracy\n",
    "    'min_samples_split': [5, 10, 15],  # Allow splits at a reasonable level\n",
    "    'min_samples_leaf': [2, 4, 6],  # Ensure smaller leaf nodes to capture patterns\n",
    "    'splitter': ['best'],  # Deterministic behavior\n",
    "    'ccp_alpha': [0.001, 0.005, 0.01]  # Moderate pruning for controlled growth\n",
    "}\n",
    "\n",
    "print(\"Running Decision Tree with 10 folds:\")\n",
    "run_decision_tree(param_grid_2)\n",
    "\n",
    "print(\"\\nRunning Decision Tree with 20 folds:\")\n",
    "run_decision_tree(param_grid_2, folds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5008c487-4096-4a4d-bac9-fbc89e9728b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_grid_3 = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [10, 12, 15],  # Reducing depth for better generalization\n",
    "    'min_samples_split': [15, 20, 25],  # Larger splits to avoid small branches\n",
    "    'min_samples_leaf': [6, 7, 8],  # Ensures minimum samples per leaf\n",
    "    'splitter': ['best'],  # Keeping only deterministic behavior\n",
    "    'ccp_alpha': [0.01, 0.05, 0.1]  # Stronger pruning for simplicity\n",
    "}\n",
    "\n",
    "print(\"Running Decision Tree with 10 folds:\")\n",
    "run_decision_tree(param_grid_3)\n",
    "\n",
    "print(\"\\nRunning Decision Tree with 20 folds:\")\n",
    "run_decision_tree(param_grid_3, folds=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253247e3-b43a-4b38-9d29-6c80fb350d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_4 = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [9, 12, 15],  # Increased to allow deeper insights\n",
    "    'min_samples_split': [2, 5, 10],  # Slightly lower split requirement\n",
    "    'min_samples_leaf': [1, 2, 4],  # Allows for better granularity\n",
    "    'splitter': ['best'],  # Deterministic behavior\n",
    "    'ccp_alpha': [0.0005, 0.001, 0.005]  # Fine-tuned pruning\n",
    "}\n",
    "\n",
    "print(\"Running Decision Tree with 10 folds:\")\n",
    "run_decision_tree(param_grid_4)\n",
    "\n",
    "print(\"\\nRunning Decision Tree with 20 folds:\")\n",
    "run_decision_tree(param_grid_4, folds=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaf2438-5379-4380-b670-0f4e81163578",
   "metadata": {},
   "source": [
    "## Runs with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143d6e80-f344-4ca4-9820-6ab171c055c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "param_grid_1 = {\n",
    "    'n_estimators': [50, 100],  # Reduce tree count to prevent excessive fitting\n",
    "    'criterion': ['entropy'],  \n",
    "    'max_depth': [5, 10],  # Strict depth limit\n",
    "    'min_samples_split': [10, 20],  # Require more samples to split\n",
    "    'min_samples_leaf': [4, 6],  # Larger leaf size for regularization\n",
    "    'ccp_alpha': [0.01, 0.05, 0.1],  # Stronger pruning\n",
    "    'max_features': ['log2']  # Limit feature selection to prevent memorization\n",
    "}\n",
    "run_random_forest(param_grid_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2b1ed-f987-4218-bd80-804a29192e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_grid_2 = {\n",
    "    'n_estimators': [100],  \n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [15],  \n",
    "    'min_samples_split': [20],  \n",
    "    'min_samples_leaf': [6],  \n",
    "    'ccp_alpha': [0.01],  \n",
    "    'max_features': ['log2']\n",
    "}\n",
    "run_random_forest(param_grid_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89599125",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_3 = {\n",
    "    'n_estimators': [10],  \n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [5, 10],  \n",
    "    'min_samples_split': [10, 20],  \n",
    "    'min_samples_leaf': [4, 6],  \n",
    "    'ccp_alpha': [0.01, 0.1],  \n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "run_random_forest(param_grid_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6786a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid_4 = {\n",
    "    'n_estimators': [50],  \n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [10, 15],  \n",
    "    'min_samples_split': [10, 20],  \n",
    "    'min_samples_leaf': [4, 6],  \n",
    "    'ccp_alpha': [0.01],  \n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "run_random_forest(param_grid_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b85b8",
   "metadata": {},
   "source": [
    "## Runs of Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b2cddb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Run  Accuracy (%)                                    Best Parameters\n",
      "0  3-Fold CV        99.968  {'n_neighbors': 30, 'p': 1, 'weights': 'distan...\n",
      "1  5-Fold CV        99.968  {'n_neighbors': 30, 'p': 1, 'weights': 'distan...\n"
     ]
    }
   ],
   "source": [
    "param_grid_knn = {\n",
    "    'n_neighbors': [30, 33 ,39],  # Balanced number of neighbors\n",
    "    'p': [1, 2],  # Manhattan (p=1) and Euclidean (p=2) distances\n",
    "    'weights': ['distance']  # Avoid distance weighting to prevent overfitting\n",
    "}\n",
    "\n",
    "# Run KNN with 10-Fold and 20-Fold Cross-Validation\n",
    "results = []\n",
    "for folds in [3, 5]:\n",
    "    accuracy, best_params = run_knn(param_grid_knn, folds=folds)\n",
    "    results.append((f\"{folds}-Fold CV\", accuracy, best_params))\n",
    "\n",
    "# Convert results to DataFrame and print\n",
    "df_results = pd.DataFrame(results, columns=['Run', 'Accuracy (%)', 'Best Parameters'])\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7fd15a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Run  Accuracy (%)                                    Best Parameters\n",
      "0  3-Fold CV         99.98  {'n_neighbors': 15, 'p': 1, 'weights': 'distan...\n",
      "1  5-Fold CV         99.98  {'n_neighbors': 15, 'p': 1, 'weights': 'distan...\n"
     ]
    }
   ],
   "source": [
    "param_grid_knn = {\n",
    "    'n_neighbors': [15, 17, 19],  # Balanced number of neighbors\n",
    "    'p': [1, 2],  # Manhattan (p=1) and Euclidean (p=2) distances\n",
    "    'weights': ['distance']  # Avoid distance weighting to prevent overfitting\n",
    "}\n",
    "\n",
    "# Run KNN with 10-Fold and 20-Fold Cross-Validation\n",
    "results = []\n",
    "for folds in [3, 5]:\n",
    "    accuracy, best_params = run_knn(param_grid_knn, folds=folds)\n",
    "    results.append((f\"{folds}-Fold CV\", accuracy, best_params))\n",
    "\n",
    "# Convert results to DataFrame and print\n",
    "df_results = pd.DataFrame(results, columns=['Run', 'Accuracy (%)', 'Best Parameters'])\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bfd206b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Run  Accuracy (%)                                    Best Parameters\n",
      "0  3-Fold CV        99.986  {'n_neighbors': 9, 'p': 1, 'weights': 'distance'}\n",
      "1  5-Fold CV        99.986  {'n_neighbors': 9, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "param_grid_knn = {\n",
    "    'n_neighbors': [9, 11, 13],  # Balanced number of neighbors\n",
    "    'p': [1, 2],  # Manhattan (p=1) and Euclidean (p=2) distances\n",
    "    'weights': ['distance']  # Avoid distance weighting to prevent overfitting\n",
    "}\n",
    "\n",
    "# Run KNN with 10-Fold and 20-Fold Cross-Validation\n",
    "results = []\n",
    "for folds in [3, 5]:\n",
    "    accuracy, best_params = run_knn(param_grid_knn, folds=folds)\n",
    "    results.append((f\"{folds}-Fold CV\", accuracy, best_params))\n",
    "\n",
    "# Convert results to DataFrame and print\n",
    "df_results = pd.DataFrame(results, columns=['Run', 'Accuracy (%)', 'Best Parameters'])\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dfb73017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Run  Accuracy (%)                                    Best Parameters\n",
      "0  3-Fold CV        99.986  {'n_neighbors': 8, 'p': 1, 'weights': 'distance'}\n",
      "1  5-Fold CV        99.986  {'n_neighbors': 8, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "param_grid_knn = {\n",
    "    'n_neighbors': [8, 11, 12],  # Balanced number of neighbors\n",
    "    'p': [1, 2],  # Manhattan (p=1) and Euclidean (p=2) distances\n",
    "    'weights': ['distance']  # Avoid distance weighting to prevent overfitting\n",
    "}\n",
    "\n",
    "# Run KNN with 10-Fold and 20-Fold Cross-Validation\n",
    "results = []\n",
    "for folds in [3, 5]:\n",
    "    accuracy, best_params = run_knn(param_grid_knn, folds=folds)\n",
    "    results.append((f\"{folds}-Fold CV\", accuracy, best_params))\n",
    "\n",
    "# Convert results to DataFrame and print\n",
    "df_results = pd.DataFrame(results, columns=['Run', 'Accuracy (%)', 'Best Parameters'])\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c729b3de-8899-4261-8d15-fdbbed8565af",
   "metadata": {},
   "source": [
    "## Result\n",
    "Judging from above runs, it is found that between Random forest and Decision tree, the Random forest classification is giving better results. Therefor, I will be choosing the best Accuracy result from Random forest runs for making the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c8668ec0-bc58-424c-8939-157eed17f737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Best parameters: {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Fold 1: Accuracy: 98.50%\n",
      "Fold 1: Confusion Matrix:\n",
      "[[2138   30]\n",
      " [  45 2787]]\n",
      "\n",
      "Fold 2: Best parameters: {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Fold 2: Accuracy: 98.84%\n",
      "Fold 2: Confusion Matrix:\n",
      "[[2211   22]\n",
      " [  36 2731]]\n",
      "\n",
      "Fold 3: Best parameters: {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 15}\n",
      "Fold 3: Accuracy: 98.82%\n",
      "Fold 3: Confusion Matrix:\n",
      "[[2164   31]\n",
      " [  28 2777]]\n",
      "\n",
      "Fold 4: Best parameters: {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Fold 4: Accuracy: 99.10%\n",
      "Fold 4: Confusion Matrix:\n",
      "[[2149   19]\n",
      " [  26 2806]]\n",
      "\n",
      "Fold 5: Best parameters: {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Fold 5: Accuracy: 98.88%\n",
      "Fold 5: Confusion Matrix:\n",
      "[[2195   22]\n",
      " [  34 2749]]\n",
      "\n",
      "Fold 6: Best parameters: {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 15}\n",
      "Fold 6: Accuracy: 98.02%\n",
      "Fold 6: Confusion Matrix:\n",
      "[[2188   53]\n",
      " [  46 2713]]\n",
      "\n",
      "Fold 7: Best parameters: {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Fold 7: Accuracy: 98.86%\n",
      "Fold 7: Confusion Matrix:\n",
      "[[2257   16]\n",
      " [  41 2686]]\n",
      "\n",
      "Fold 8: Best parameters: {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
      "Fold 8: Accuracy: 98.74%\n",
      "Fold 8: Confusion Matrix:\n",
      "[[2182   14]\n",
      " [  49 2755]]\n",
      "\n",
      "Fold 9: Best parameters: {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 15}\n",
      "Fold 9: Accuracy: 98.66%\n",
      "Fold 9: Confusion Matrix:\n",
      "[[2276   15]\n",
      " [  52 2657]]\n",
      "\n",
      "Fold 10: Best parameters: {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Fold 10: Accuracy: 98.58%\n",
      "Fold 10: Confusion Matrix:\n",
      "[[2243    8]\n",
      " [  63 2686]]\n",
      "\n",
      "\n",
      "===== FINAL RESULTS =====\n",
      "Mean Accuracy over 10 folds: 98.70%\n",
      "Standard Deviation: 0.28%\n",
      "Total Execution Time: 225.24 seconds\n",
      "\n",
      "Best Parameters Overall: {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Best Decision Tree model saved to best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [10, 15, 20],  \n",
    "    'min_samples_split': [5, 10, 15],  \n",
    "    'min_samples_leaf': [2, 4, 6],  \n",
    "    'ccp_alpha': [0.001, 0.005, 0.01]  \n",
    "}\n",
    "\n",
    "# Function to run Decision Tree with cross-validation and select the best model\n",
    "def run_decision_tree(param_grid, folds=10):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    best_model = None\n",
    "    best_params_overall = None\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Initialize DecisionTreeClassifier\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        \n",
    "        # Use GridSearchCV to find the best parameters\n",
    "        grid_search = GridSearchCV(clf, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_  # Store the best model from the final fold\n",
    "        best_params_overall = best_params\n",
    "        \n",
    "        print(f\"Fold {fold}: Best parameters: {best_params}\")\n",
    "        \n",
    "        y_pred = best_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        print(f\"Fold {fold}: Accuracy: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"Fold {fold}: Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"\\n===== FINAL RESULTS =====\")\n",
    "    print(f\"Mean Accuracy over {folds} folds: {mean_accuracy * 100:.2f}%\")\n",
    "    print(f\"Standard Deviation: {std_accuracy * 100:.2f}%\")\n",
    "    print(f\"Total Execution Time: {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"\\nBest Parameters Overall: {best_params_overall}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Run the Decision Tree model and obtain the best model\n",
    "best_model = run_decision_tree(param_grid, folds=10)\n",
    "\n",
    "# Save the best Decision Tree model to a pickle file\n",
    "model_filename = 'best_model.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(f\"Best Decision Tree model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb6093c-be86-4003-ac97-8d99ea4dc04c",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c7137-d2ab-409c-8b98-d0d44b2b8247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy of the loaded model on the test set: 98.48%\n",
      "\n",
      "Confusion Matrix on Test Data:\n",
      "[[22164    69]\n",
      " [  691 27076]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model_filename = \"best_model.pkl\"  # Ensure correct model file name\n",
    "with open(model_filename, \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Load the test dataset\n",
    "test_file = \"mushroom_mixed_50000.csv\"\n",
    "test_data = pd.read_csv(test_file)\n",
    "\n",
    "# Set the correct target column\n",
    "target_col = \"class\"  # Represents edible ('e') or poisonous ('p')\n",
    "\n",
    "# Separate features and target variable\n",
    "X_test = test_data.drop(columns=[target_col], errors=\"ignore\")  # Features\n",
    "y_test = test_data[target_col]  # Target variable\n",
    "\n",
    "# Apply label encoding to match the trained model\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)  # Converts 'e'/'p' into 0/1\n",
    "\n",
    "# Ensure categorical variables are encoded as they were during training\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "X_test_encoded = pd.DataFrame(encoder.fit_transform(X_test.select_dtypes(include=[\"object\"])))\n",
    "\n",
    "# Rename columns with original names\n",
    "X_test_encoded.columns = encoder.get_feature_names_out(X_test.select_dtypes(include=[\"object\"]).columns)\n",
    "\n",
    "# Add back numerical columns\n",
    "X_test_final = X_test_encoded.join(X_test.select_dtypes(exclude=[\"object\"]).reset_index(drop=True))\n",
    "\n",
    "# Ensure features are in the same order as training\n",
    "expected_features = loaded_model.feature_names_in_\n",
    "X_test_final = X_test_final.reindex(columns=expected_features, fill_value=0)  # Fill missing features with 0\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = loaded_model.predict(X_test_final)\n",
    "\n",
    "# Compute accuracy\n",
    "test_accuracy = accuracy_score(y_test_encoded, y_pred_test)  # Use encoded y_test\n",
    "print(f\"\\n✅ Accuracy of the loaded model on the test set: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_test)  # Compare encoded labels\n",
    "print(\"\\nConfusion Matrix on Test Data:\")\n",
    "print(cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
